---
title: "A Stylometric Analysis of Senecaâ€™s disputed plays:\nApplying Computational Stylistics on Octavia and Hercules Oetaeus"
output: html_notebook
---
# Introduction
In this notebook we will apply Bootstrap Consensus Tree (henceforward: BCT) and Principal Component Analysis (henceforward: PCA); for the latter we will use a covariance and a correlation matrix to visualise the results.
The same preprocessing step will be applied to every text that is used here and the results will be generated using Most Frequent Characters (henceforward MFCs) tetragrams and pentagrams.

```{r}
library(stylo)
library(gplots)
library(pheatmap)
```

# Setting the working directory

```{r}
setwd("../analysis")
getwd()
```
# Importing the corpus and tokenisation

In this step we import the corpus that we are going to use and consequently we tokenize it. The tokenisation follows the rules of the parameter `Latin.corr`. This is done because a lot of texts do not distinguish "u/v" and by setting this parameter to `Latin.corr` we take care of this variation in the letters. Moreover, we change uppercase letters to lowercase. Lastly, 

```{r}
raw.corpus <- load.corpus(files = "all", corpus.dir = "corpus",
                          encoding = "UTF-8")

tokenized.corpus <- txt.to.words.ext(raw.corpus, corpus.lang = "Latin.corr", 
                                     preserve.case = FALSE)
```

# Remove the pronouns
It was decided to remove the pronouns, since some pronouns are connected to the genre of the text.
```{r}
corpus.no.pronouns <- delete.stop.words(tokenized.corpus,
                                        stop.words = stylo.pronouns(corpus.lang = "Latin.corr"))
```
# Extracting the features
The final step before proceeding to the method per se is to extract the features that we want to use and add them to a table with frequencies. In our case, we want to extract character tetra-grams and penta-grams.
```{r}
corpus.char.4.grams <- txt.to.features(corpus.no.pronouns, ngram.size = 4,
                                       features = "c")

corpus.char.5.grams <- txt.to.features(corpus.no.pronouns, ngram.size = 5,
                                       features = "c")


frequent.features.4grams <- make.frequency.list(corpus.char.4.grams, 
                                                head = 3000)

freqs.4grams <- make.table.of.frequencies(corpus.char.4.grams,
                                   features = frequent.features.4grams, relative = TRUE)

frequent.features.5grams <- make.frequency.list(corpus.char.5.grams,
                                                head = 3000)


freqs.5grams <- make.table.of.frequencies(corpus.char.5.grams,
                                          features = frequent.features.5grams, relative = TRUE)
```
# Apply BCT
```{r}
# BCT 4grams
bct.results.4grams = stylo(corpus.dir = "corpus", frequencies = freqs.4grams, distance.measure = "eder",
                           analysis.type = "BCT", mfw.min = 100, mfw.max = 1500, 
                           increment = 100, consensus.strength = 0.6, gui = TRUE)
```

# BCT 5grams

```{r}
bct.results.5grams = stylo(corpus.dir = "corpus", frequencies = freqs.5grams, distance.measure = "eder",
                           analysis.type = "BCT", mfw.min = 100, mfw.max = 1500, 
                           increment = 100, consensus.strength = 0.6, gui = TRUE)
```
```{r}
# 4grams

summary(bct.results.4grams)
bct.results.4grams$distance.table

col <- colorRampPalette(rev(RColorBrewer::brewer.pal(n = 9, name = "Reds")))(9)

pheatmap(as.matrix(bct.results.4grams$distance.table), color = col, 
         display_numbers = TRUE,  number_format = "%.1f", fontsize_number = 6,
         main = "Heatmap with the Eder's Delta distances\nbetween the texts in the corpus",
         treeheight_row = 70, treeheight_col = 70, number_color = "black",
         legend = TRUE, border_color = "black", angle_col = 45)

```

```{r}
#5grams

summary(bct.results.5grams)
bct.results.5grams$distance.table

col <- colorRampPalette(rev(RColorBrewer::brewer.pal(n = 9, name = "Reds")))(9)

pheatmap(as.matrix(bct.results.5grams$distance.table), color = col, 
         display_numbers = TRUE,  number_format = "%.1f", fontsize_number = 6,
         main = "Heatmap with the Eder's Delta distances\nbetween the texts in the corpus",
         treeheight_row = 70, treeheight_col = 70, number_color = "black",
         legend = TRUE, border_color = "black", angle_col = 45)

```
# Principal Component Analysis
Now we will apply PCA using covariance and correlation matrix to the Senecan corpus of texts. We will follow exactly the same steps as before only that now we will process the `corpus_seneca` repository, which contains only the plays written by Seneca the Younger.

# Importing the corpus and tokenisation

In this step we import the corpus that we are going to use and consequently we tokenize it. The tokenisation follows the rules of the parameter `Latin.corr`. This is done because a lot of texts do not distinguish "u/v" and by setting this parameter to `Latin.corr` we take care of this variation in the letters. Moreover, we change uppercase letters to lowercase. Lastly, 

```{r}
raw.corpus.seneca <- load.corpus(files = "all", corpus.dir = "corpus_seneca",
                          encoding = "UTF-8")

tokenized.corpus.seneca <- txt.to.words.ext(raw.corpus.seneca, corpus.lang = "Latin.corr", 
                                     preserve.case = FALSE)
```

# Remove the pronouns
It was decided to remove the pronouns, since some pronouns are connected to the genre of the text.
```{r}
corpus.seneca.no.pronouns <- delete.stop.words(tokenized.corpus.seneca,
                                               stop.words = stylo.pronouns(corpus.lang = "Latin.corr"))
```
# Extracting the features
The final step before proceeding to the method per se is to extract the features that we want to use and add them to a table with frequencies. In our case, we want to extract character tetra-grams and penta-grams.

```{r}
# 4grams
corpus.seneca.char.4.grams <- txt.to.features(corpus.seneca.no.pronouns, ngram.size = 4,
                                              features = "c")



frequent.features.4grams <- make.frequency.list(corpus.seneca.char.4.grams, 
                                                head = 3000)

freqs.seneca.4grams <- make.table.of.frequencies(corpus.seneca.char.4.grams,
                                          features = frequent.features.4grams, relative = TRUE)


# 5grams
corpus.seneca.char.5.grams <- txt.to.features(corpus.seneca.no.pronouns, ngram.size = 5,
                                              features = "c")

frequent.features.5grams <- make.frequency.list(corpus.seneca.char.5.grams,
                                                head = 3000)


freqs.seneca.5grams <- make.table.of.frequencies(corpus.seneca.char.5.grams,
                                          features = frequent.features.5grams, relative = TRUE)
```

# Apply PCA
```{r}
# 4grams covariance

results_pca_4grams_cov = stylo(frequencies = freqs.seneca.4grams, analysis.type = "PCR",
                               mfw.min = 100, mfw.max = 1500, distance.measure = "eder", 
                               custom.graph.title = "Seneca against himself", gui = TRUE)
```

```{r}
#4 grams correlation
results_pca_4grams_cor = stylo(frequencies = freqs.seneca.4grams, analysis.type = "PCR",
                               mfw.min = 100, mfw.max = 1500, distance.measure = "eder", 
                               custom.graph.title = "Seneca against himself", gui = TRUE)

```

```{r}
# 5grams covariance
results_pca_5grams_cov = stylo(frequencies = freqs.seneca.5grams, analysis.type = "PCR",
                               mfw.min = 100, mfw.max = 200, distance.measure = "eder", 
                               custom.graph.title = "Seneca against himself", gui = TRUE)
```


```{r}
# 5grams correlation
results_pca_5grams_cor = stylo(frequencies = freqs.seneca.5grams, analysis.type = "PCR",
                               mfw.min = 100, mfw.max = 1500, distance.measure = "eder", 
                               custom.graph.title = "Seneca against himself", gui = TRUE)
```

