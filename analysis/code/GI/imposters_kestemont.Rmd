---
title: "R Notebook"
author: "Paschalis Agapitos"
output:
  # pdf_document: default
  # html_notebook: default
---
# Introduction
In this notebook we will run the `imposters()` method using Kestemont's corpus. In this corpus there are 1814 texts but a great limitation of it is that almost all of the texts are are in prose. We have added to this dataset the authors of the Neronian literature such Lucan, Persius, and Statius. Of course we have added the Senecan texts as well.

We will first run the scenario of character 4-grams and consequently the scenarion of character 5-grams. The same preprocessing will be applied to every scenario. Lastly, we will also test the scenario of splitting the *Hercules Oetaeus* in half.

# Importing the libraries

```{r}
library(stylo)
set.seed(0)
```

# Setting working directory

The first step that we need to take is to set the working directory to the folder where this notebook and our dataset are saved. In our case `Analysis` is our working directory.

```{r}
setwd("../analysis/")
getwd()
```

# Preparation of the dataset

The "preparation of the dataset" step consists of six steps.

1)  importing the corpus; at this step we need to make sure that we point out to the correct directory.
2)  tokenizing the corpus, lowering the case of the letters and removing punctuation marks. A very crucial detail on which we should pay attention is the the aspect of the language. Our dataset is written in Latin, so we could either use the `Latin` or `Latin.corr` in the parameter `lang`. Since a lot of manuscripts in Latin do not distinguish the letter `v` from the letter `u`, the second option suits better in this case.
3)  removing the pronouns; this step is optional but since some studies have shown that pronouns are related to the genre or content of a text, it was decided for them to be removed.
4)  extracting the features that we want to use; in our case character tetra-grams and penta-grams will be used.
5)  creating the frequency list
6)  creating the table with frequencies using the frequency list that was created in the previous step.

```{r}
# step 1
raw.corpus <- load.corpus(
  files = "all",
  corpus.dir = "corpus_kestemont/",
  encoding = "UTF-8"
)
```

```{r}
# step 2
tokenized.corpus <- txt.to.words.ext(
    raw.corpus,
    corpus.lang = "Latin.corr",
    preserve.case = F,
)
```

```{r}
# step 3
corpus.no.pronouns <- delete.stop.words(
  tokenized.corpus,
  stop.words = stylo.pronouns(corpus.lang = "Latin.corr")
)

summary(corpus.no.pronouns)
```


```{r}
# step 4
corpus.char.tetragrams <- txt.to.features(
  tokenized.text = corpus.no.pronouns,
  features = "c",
  ngram.size = 4
)
```

```{r}
# step 5
features_char_tetragrams <- make.frequency.list(
  corpus.char.tetragrams,
  head = 3000
)
```

```{r}
# step 6
data = make.table.of.frequencies(
  corpus = corpus.char.tetragrams,
  features = features_char_tetragrams,
  relative = T
)
```
# Implementation of `imposters` method
In order to implement `imposters` to the data that we have prepared in the previous steps we first need to find in which rows the disputed texts are. This will help us when we need to split the dataset into reference and test set; we could do that just by referring to the number of the row where the texts under investigation are.

```{r}
options(max.print=2000)
rownames(data)
```

We can see that Octavia is at the *1364th row* and Hercules Oetaeus at the *1293th row*.

```{r}
help("imposters")
# according to Koppel and Winter(2014) the number of iteration does not change the result of the classification, thus iterations = 100 (default value)

imposters.kestemont.octavia <- imposters(
  reference.set = data[-c(1364), 1:1500],
  test = data[1364, 1:1500],
  iterations = 100,
  distance = 'eder'
)
```
```{r}
print("Octavia vs Kestemont's corpus (1-1500 MFCs 4-grams):")
print(imposters.kestemont.octavia)
```
The next phase is to apply the same method on the other disputed text, Hercules Oetaeus.
```{r}
imposters.kestemont.hero <- imposters(
  reference.set = data[-c(1293), 1:1500],
  test = data[1293, 1:1500],
  iterations = 100,
  distance = 'eder'
)
```

```{r}
print("Hercules Oetaues vs Kestemont's corpus (1-1500 MFCs 4-grams):")
print(imposters.kestemont.hero)
```

# Optimize

The `imposters` method comes with an in-built function that optimizes the hyperparameters used in the General Imposters method. In other words it tries to define the grey area where these result could be valid or not.

```{r}
# help("imposters.optimize")
imposters.optimize(data)
```
Let's do the same for character 5-grams.
```{r}
# step 4
corpus.char.pentagrams <- txt.to.features(
  tokenized.text = corpus.no.pronouns,
  features = "c",
  ngram.size = 5
)
```

```{r}
# step 5
features_char_pentagrams <- make.frequency.list(
  corpus.char.pentagrams,
  head = 3000
)
```

```{r}
# step 6
data = make.table.of.frequencies(
  corpus = corpus.char.pentagrams,
  features = features_char_pentagrams,
  relative = T
)
```

```{r}
imposters.kestemont.octavia.5grams <- imposters(
  reference.set = data[-c(1364), 1:1500],
  test = data[1364, 1:1500],
  iterations = 100,
  distance = 'eder'
)
```
Hercules Oetaeus
```{r}
imposters.kestemont.hero.5grams <- imposters(
  reference.set = data[-c(1293), 1:1500],
  test = data[1293, 1:1500],
  iterations = 100,
  distance = 'eder'
)
```
```{r}
print("Octavia vs Kestemont's corpus (1-1500 MFCs 4-grams):")
print(imposters.kestemont.octavia.5grams)
```

```{r}
print("Hercules Oetaeus vs Kestemont's corpus (1-1500 MFCs 5-grams):")
imposters.kestemont.hero.5grams
```

We will follow exactly the same approach now but we will apply `imposters()` to the chunks of *Hercules Oetaeus* instead of the actual text. We have split *Hercules Oetaeus* exactly in half and we have two separate txt files named `sen_hero_chunk1.txt` and `sen_hero_chunk1.txt` accordingly.

The only thing you need to do to run this version of the experiment is that you need to find inside `corpus_kestemont` the file `sene_hero3.txt` and replace it with the aforementioned files.
```{r}
# step 1
raw.corpus <- load.corpus(
  files = "all",
  corpus.dir = "corpus_kestemont/",
  encoding = "UTF-8"
)
```

```{r}
# step 2
tokenized.corpus <- txt.to.words.ext(
    raw.corpus,
    corpus.lang = "Latin.corr",
    preserve.case = F,
)
```

```{r}
# step 3
corpus.no.pronouns <- delete.stop.words(
  tokenized.corpus,
  stop.words = stylo.pronouns(corpus.lang = "Latin.corr")
)

summary(corpus.no.pronouns)
```
For Character 4-grams:
```{r}
# step 4
corpus.char.tetragrams <- txt.to.features(
  tokenized.text = corpus.no.pronouns,
  features = "c",
  ngram.size = 4
)
```

```{r}
# step 5
features_char_tetragrams <- make.frequency.list(
  corpus.char.tetragrams,
  head = 3000
)
```

```{r}
# step 6
data = make.table.of.frequencies(
  corpus = corpus.char.tetragrams,
  features = features_char_tetragrams,
  relative = T
)
```
```{r}
rownames(data) # HO chunk1 1292, HO chunk2 1293
```

```{r}
# for the 1st chunk of Hercules Oetaeus (1292th row)
imposters.kestemont.hero.chunk1.4grams <- imposters(
  reference.set = data[-c(1292), 1:1500],
  test = data[1292, 1:1500],
  iterations = 100,
  distance = 'eder'
)
```

```{r}
# for the 2nd chunk of Hercules Oetaeus (1293th row)
imposters.kestemont.hero.chunk2.4grams <- imposters(
  reference.set = data[-c(1293), 1:1500],
  test = data[1293, 1:1500],
  iterations = 100,
  distance = 'eder'
)
```

```{r}
print("Hercules Oetaeus chunk 1 vs Kestemont's corpus (1-1500 MFCs 4-grams):")
imposters.kestemont.hero.chunk1.4grams
```


```{r}
print("Hercules Oetaeus chunk 2 vs Kestemont's corpus (1-1500 MFCs 4-grams):")
imposters.kestemont.hero.chunk2.4grams
```