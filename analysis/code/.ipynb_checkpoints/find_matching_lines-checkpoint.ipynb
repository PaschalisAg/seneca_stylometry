{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3a676752",
   "metadata": {},
   "source": [
    "---\n",
    "title: Fuzzy String Matching\n",
    "author: Paschalis Agapitos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93336152",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The basic intuition behind Fuzzy String Matching (also known as: Approximate String Matching) is fuzzy logic. Fixed logic is not fixed and exact but rather approximate. In terms of numbers, this kind of logic returns a number between 0 and 1 and it is completely different from the boolean logic which returns either `0` or `1` (`True` or `False`).\n",
    "\n",
    "Therefore following this intuition we can compare two strings and find how similar they are to each other; just like plagiarism works since we are not looking only for identical sentences but for similar sentences as well.\n",
    "\n",
    "To do this, we will exploit Python's library [`fuzzywuzzy`](https://pypi.org/project/fuzzywuzzy/). According to the documentation, this library \"uses the [Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) to calculate the differences between sequences\".\n",
    "\n",
    "There are a lot of function that this library contains that they can find similar lines. Some of them are the following:\n",
    "- `ratio()`\n",
    "- `partial_ratio()`\n",
    "- `token_set_ratio()`\n",
    "- `token_sort_ration()`\n",
    "\n",
    "Even though `ratio()`, `partial_ratio()`, `token_set_ratio()`, and `token_sort_ratio()` functions from the `fuzzywuzzy` library are all suitable for comparing strings for similarity. However, when it comes to finding reworked lines in two texts, they may not always be the best choice.\n",
    "\n",
    "- `ratio()` and `partial_ratio()` functions only compare two strings character-by-character and compute their similarity as a ratio of the number of matching characters to the total number of characters. While these functions can detect similar lines, they may not be able to distinguish between verbatim and reworked lines.\n",
    "\n",
    "- `token_set_ratio()` and `token_sort_ratio()` functions compare two strings based on the set of their unique tokens or sorted tokens, respectively. These functions can handle reordering and additional tokens in the compared strings, but they still do not distinguish between verbatim and reworked lines.\n",
    "\n",
    "When comparing two texts for reworked lines, you may need to consider the context and the meaning of the lines. \n",
    "Two lines may have different words but convey the same meaning, or they may have the same words but different meanings in different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45543d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-02T20:16:08.017535Z",
     "start_time": "2023-04-02T19:20:05.371041Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "def remove_punctuation(filename):\n",
    "    text = \"\"\n",
    "    with open(filename, 'r') as inp:\n",
    "        text = inp.read()\n",
    "    # remove punctuation from each text\n",
    "    text_no_punctuation = re.sub(r'[^\\w\\s\\n]', '', text)\n",
    "    # split into lines to maintain the original format\n",
    "    lines = text_no_punctuation.splitlines()\n",
    "    # join the texts into a string again\n",
    "    text = \"\\n\".join(lines)\n",
    "    return text\n",
    "\n",
    "\n",
    "# read the disputed text and remove punctuation\n",
    "disputed_text_octavia = remove_punctuation(\n",
    "    '../verse_corpus_imposters/sen_oct.txt')\n",
    "\n",
    "\n",
    "# define a function that will merge all the original texts into a list\n",
    "# this is a prerequisite for the extract() function to work\n",
    "# https://github.com/seatgeek/fuzzywuzzy/blob/master/fuzzywuzzy/process.py\n",
    "def merge_original_texts(directory):\n",
    "    known_texts = list()\n",
    "    for filename in glob(directory):\n",
    "        # exclude Octavia and Hercules Oetaeus\n",
    "        if filename != \"../verse_corpus_imposters/sen_her_o.txt\" and filename != \"../verse_corpus_imposters/sen_oct.txt\":\n",
    "            known_texts.append(remove_punctuation(filename))\n",
    "    return known_texts\n",
    "\n",
    "\n",
    "# define a function that will compare the similarity of lines from the disputed text\n",
    "# against all the other texts in a given corpus\n",
    "def find_similar_lines(disputed_text, non_disputed_text, output_filename):\n",
    "    \"\"\"\n",
    "    requirements:\n",
    "     - python >= 2.7\n",
    "     - difflib\n",
    "     - python-Levenshtein\n",
    "    \"\"\"\n",
    "    # split into lines for the disputed text\n",
    "    lines_disputed_text = disputed_text.splitlines()\n",
    "    # split into lines for the original text(s)\n",
    "    lines_non_disp_text = [line.splitlines() for line in non_disputed_text]\n",
    "    matching_lines = []  # list to populate with the matching lines\n",
    "    for disputed_line_num, disputed_line in enumerate(lines_disputed_text):\n",
    "        for non_disputed_line_num, non_disputed_line in enumerate(lines_non_disp_text):\n",
    "            matches = process.extract(\n",
    "                disputed_line, non_disputed_line, limit=None)\n",
    "            if matches[0][1] >= 80:\n",
    "                matching_lines.append((\n",
    "                    disputed_line,  # disputed line text\n",
    "                    matches[0][0],  # matching line in original text\n",
    "                    matches[0][1],  # matching score\n",
    "                ))\n",
    "    with open(output_filename, 'w') as out:\n",
    "        for line in matching_lines:\n",
    "            out.write(\"Disputed line: {}\\n\".format(line[0]))\n",
    "            out.write(\"Matching line: {}\\n\".format(line[1]))\n",
    "            out.write(\"Similarity score: {}\\n\\n\".format(line[2]))\n",
    "\n",
    "\n",
    "# set the path to the directory containing the original texts\n",
    "path_to_corpus = \"../verse_corpus_imposters/*.txt\"\n",
    "\n",
    "# merge all the original texts into a single list\n",
    "original_texts = merge_original_texts(path_to_corpus)\n",
    "\n",
    "# find matching lines and write them to a file\n",
    "output_filename = \"matching_lines_octavia.txt\"\n",
    "find_similar_lines(disputed_text_octavia, original_texts, output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
