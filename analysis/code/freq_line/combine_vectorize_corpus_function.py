import os
from sklearn.feature_extraction.text import CountVectorizer
import matplotlib.pyplot as plt
import seaborn as sns

# define a function to read all text files in a directory and combine them into a single string


def read_and_combine_corpus(directory):
    """
    Help on function read_and_combine_corpus:

    This function will check for `.txt` files` and for each `.txt` file that it finds it will add it
    into one string. The result is every file of a directory to become a single string.

    - `directory`: the directory that contains the files that you want to combine in a single string.
    """
    corpus = ""
    for filename in os.listdir(directory):
        # check for this condition, otherwise listdir takes into account binary files
        if filename.endswith(".txt"):
            with open(os.path.join(directory, filename), 'r') as f:
                text = f.read().strip()
                corpus += text  # combine every text into one corpus
    return corpus

# define a function that vectorizes the string generated by the previous function


def vectorize_texts(max_features, analyzer, ngram_range, corpus_filename, reverse):
    """
    Help on function vectorize_texts:

    - `max_features`: the number of features you want the matrix to have. E.g., if max_features=2000,
    then only the top 2000 most frequent features will be returned.

    - `analyzer`: {'word', 'char', 'char_wb'} or callable, default='word'
    Whether the feature should be made of word n-gram or character n-grams.
    Option 'char_wb' creates character n-grams only from text inside
    word boundaries; n-grams at the edges of words are padded with space.

    - `ngram_range`: tuple (min_n, max_n), default=(1, 1)
    The lower and upper boundary of the range of n-values for different
    word n-grams or char n-grams to be extracted. All values of n such
    such that min_n <= n <= max_n will be used. For example an
    ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means
    unigrams and bigrams, and ``(2, 2)`` means only bigrams.
    Only applies if ``analyzer`` is not callable.

    - `corpus_to_vectorize`: a corpus of several texts that has been combined in a single string.
    See function read_and_combine.

    - `reverse`: {True, False}
    if set to True, it returns the features sorted in descending order.
    If False, then features are sorted in ascending order.
    """

    corpus = read_and_combine_corpus(corpus_filename)

    # use CountVectorizer to transform the corpus into a matrix of charcter 4-gram counts
    # return only the first 2500 character 4grams with the highest frequency | saves some memory
    vectorizer = CountVectorizer(
        max_features=max_features, analyzer=analyzer, ngram_range=ngram_range)
    X = vectorizer.fit_transform([corpus])

    # convert the matrix to a list of tuples containing the n-grams and their counts
    # toarray(): returns a dense matrix instead of a sparse matrix
    ngram_counts = list(
        zip(vectorizer.get_feature_names_out(), X.toarray()[0]))

    # sort the list in descending order of the counts:
    ngram_counts_sorted = sorted(
        ngram_counts, key=lambda x: x[1], reverse=reverse)

    # extract the counts and plot them as a line graph:
    counts = [count for word, count in ngram_counts_sorted]

    return counts


counts = vectorize_texts(max_features=10000, analyzer='char', ngram_range=(
    4, 4), corpus_filename='../verse_corpus_imposters/', reverse=True)

# plot the counts in a lineplot
sns.set_palette("colorblind")
sns.set_style("darkgrid")
# plot counts into a lineplot
ax = sns.lineplot(counts)
plt.axvline(2000, color='r', linestyle='dashed', ymax=26000)
ax.set_title(
    "Frequency Distribution\nCharacter 4grams (Verse Corpus Imposters)")
ax.set_xlabel("Character 4gram Index")
ax.set_ylabel("Frequency")
plt.ylim(0, 28000)
plt.savefig("freq_dist_char_4grams.png", dpi=300)
plt.show()
