


import os
import re
from cltk.tokenizers import LatinWordTokenizer

class TextChunkExtractor:
    def __init__(self, directory_to_read, directory_to_write, threshold_to_slice, chunk_size):
        """
        Initialize the TextChunkExtractor with directories and chunking parameters.

        Parameters:
            directory_to_read (str): The directory containing the texts to slice.
            directory_to_write (str): The directory to write the results. If it doesn't exist, it will be created.
            threshold_to_slice (int): The token count threshold above which texts will be split into chunks.
            chunk_size (int): The size of each non-overlapping chunk.
        """
        self.directory_to_read = directory_to_read
        self.directory_to_write = directory_to_write
        self.threshold_to_slice = threshold_to_slice
        self.chunk_size = chunk_size

        if not os.path.exists(self.directory_to_write):
            os.makedirs(self.directory_to_write)
            print("Directory successfully created!")
        else:
            print(f"Directory {self.directory_to_write} already exists!")

    def count_files(self, directory):
        """Count the number of .txt files in the given directory."""
        count = 0
        for path in os.scandir(directory):
            if os.path.isfile(os.path.join(directory, path)) and path.name.endswith(".txt"):
                count += 1
        return count

    def read_file(self, filepath):
        """Read the content of a file."""
        with open(filepath, 'r', encoding='utf-8') as file:
            return file.read()

    def preprocess(self, text):
        """Remove Arabic numbers from the text and return the cleaned text."""
        text = re.sub(r'[^\w\s]', '', text)
        return text

    def tokenize_latin_text(self, text):
        """Lowercase and tokenize Latin text."""
        latin_tokenizer = LatinWordTokenizer()
        text = self.preprocess(text.lower())
        tokens = latin_tokenizer.tokenize(text)
        return tokens

    def extract_chunks(self):
        """Extract chunks from text files and save them in the specified directory."""
        # process each file in the directory
        for file_name in os.listdir(self.directory_to_read):
            if file_name.endswith(".txt"):
                file_path = os.path.join(self.directory_to_read, file_name)
                tokens = self.tokenize_latin_text(self.read_file(file_path))

                if len(tokens) > self.threshold_to_slice:
                    chunks = [tokens[i:i + self.chunk_size] for i in range(0, len(tokens), self.chunk_size)]
                    for i, chunk in enumerate(chunks):
                        chunk_text = " ".join(chunk)
                        chunk_file_name = f"{file_name[:-4]}_chunk{i + 1}.txt"
                        with open(os.path.join(self.directory_to_write, chunk_file_name), "w", encoding='utf-8') as f:
                            f.write(chunk_text)
                else:
                    text = " ".join(tokens)
                    with open(os.path.join(self.directory_to_write, file_name), "w", encoding='utf-8') as f:
                        f.write(text)

        print(f"""
        Every file has been written successfully.
        The new directory (path={self.directory_to_write}) contains {self.count_files(self.directory_to_write)} text samples.""")

directory_to_read = "../../corpora/corpus_imposters/"  # get the working directory
# set the directory where you want to write the results
directory_to_write = "../../corpora/corpus_chunks/"
extractor = TextChunkExtractor(directory_to_read, directory_to_write, 500, 500)
extractor.extract_chunks()
