import pandas as pd
import matplotlib.pyplot as plt
from sklearn import metrics
import seaborn as sns


# set seaborn color palette to colorblind for accessibility
sns.set_palette('colorblind')

# read excel file
val_gi_res_cosd = pd.read_excel("../results/results_imposters_valid_cosine.xlsx")

# extract true and predicted authors from the dataframe; capitalise the first letter `title()`
true_authors = val_gi_res_cosd['real_author'].str.title()
predicted_authors = val_gi_res_cosd['attributed_author'].str.title()

# get unique class names for the confusion matrix and sort them alphabetically
class_names = sorted(true_authors.unique())


# confusion matrix
disp = metrics.ConfusionMatrixDisplay.from_predictions(
    true_authors,
    predicted_authors,
    cmap='binary',  # color map for the confusion matrix
    xticks_rotation=45,  # rotate x-axis labels for better visibility
    normalize=None  # do not normalize the confusion matrix (show counts)
)

# adjust title and labels for the confusion matrix plot
disp.ax_.set_title('Confusion matrix (imposters method; 88 texts)')
disp.ax_.set(xlabel='Predicted author', ylabel='True author')
# adjust figure size
fig = disp.figure_
fig.set_figwidth(9)
fig.set_figheight(8)
plt.tight_layout()
plt.savefig('../results/heatm_eval_gi.png', dpi=500)  # run before `plt.show()` otherwise it is not working
plt.savefig('../results/heatm_eval_gi.pdf', dpi=500)  # journal version plot
plt.show()

# display classification report for precision, recall, and F1-score
print(metrics.classification_report(true_authors,
                                    predicted_authors,
                                    zero_division=0,  # handle divisions by zero gracefully
                                    digits=2))  # show metrics with 2 decimal places
