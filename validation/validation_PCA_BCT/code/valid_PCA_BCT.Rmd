---
title: 'Validation: PCA and BCT'
author: "Paschalis Agapitos"
output: pdf_document
---

```{r, echo=FALSE}
# if not installed
install.packages("stylo")
```
Aim of this notebook is to validate the methods used in the paper A Stylometric Analysis of Seneca's Disputed Plays: Authorship Verification of Octavia and Hercules Oetaeus.

A different version of the main analysis dataset will be used now. The dataset is contained in a folder called validation_corpus. It contains 28 texts in verse written by three authors (in total 287138 tokens). The authors used in this corpus are:

    Publius Ovidius Naso (henceforward: Ovid)
        Ars Amatoria
        Epistulae
        Fasti
        Ibis
        Medicamina Faciei femineae
        Metamorphoses
        Ex Ponto
        Remedia Amoris
        Tristia
    Aulus Persius Flaccus (henceforward: Persius)
        The six books of Satires
    Publius Papinius Statius (henceforward: Statius)
        The 12 books of Thebaid

To validate the methods, we selected one text from each author (i.e., in total three texts) and renamed them with the following format: unknown{n}.txt. The authors to validate the methods are the following ones:

    Amores by Ovid (i.e., unknown0.txt)
    Thebaid book 1 by Statius (i.e., unknown1.txt)
    Satire 4 by Persius (i.e., unknown2.txt)

The first two texts were randomly chosen to be tested. However, the last one is the trickiest one because it consists of only 342 tokens.

In this notebook, we will apply Principal Component Analysis (PCA) and Bootstrap Consensus Tree (BCT); for the former we will use a covariance and a correlation matrix to visualize the results. The same preprocessing step will be applied to every text used here, and the results will be generated using Most Frequent Characters (MFCs) tetragrams and pentagrams; these n-grams will be applied to each one of the aforementioned methods and their variations.

```{r}
library(stylo)
```

# Setting the working directory

Set the working directory to `validation_PCA_BCT/`. This directory holds the data and the code to validate the PCA and BCT methods.

```{r}
knitr::opts_knit$set(root.dir = '../../validation_PCA_BCT/') # preferable for R notebook chunks
setwd('../../validation_PCA_BCT/') # run only in case of error of the previous line
getwd()
```

# Importing the corpus and tokenization
Import and tokenize the corpus. The tokenization follows the rules of the parameter `stylo.Latin.corr` to handle the variation between "u/v". Uppercase letters are converted to lowercase to minimize variations in orthography.
```{r}
# load the corpus for the validation of PCA
raw_corpus <- load.corpus(files = "all", corpus.dir = "../../validation_corpora/validation_corpus_PCA/", encoding = "UTF-8")

# tokenize the corpus
tokenized_corpus <- txt.to.words.ext(raw_corpus, corpus.lang = "Latin.corr", preserve.case = FALSE)
```

# Remove the pronouns
Remove pronouns from the corpus as they may be connected to the genre of the text.
```{r}
# remove pronouns from the tokenized corpus
corpus_no_pronouns <- delete.stop.words(tokenized_corpus, stop.words = stylo.pronouns(corpus.lang = "Latin.corr"))

# list of pronouns removed
stylo.pronouns(corpus.lang = "Latin.corr")
```

# Character 4-grams

## Extracting the features (character 4-grams)
Extract character 4-grams and add them to a frequency table.
```{r}
# extract character 4-grams
corpus_char_4grams <- txt.to.features(corpus_no_pronouns, features = "c", ngram.size = 4)

# create a frequency list of the 4-grams
frequent_features_4grams <- make.frequency.list(corpus_char_4grams, head = 2000)

# create a table of frequencies for the 4-grams
freqs_4grams <- make.table.of.frequencies(corpus_char_4grams, features = frequent_features_4grams, relative = TRUE)
```

# Method Validation - Character 4-grams

## Principal Component Analysis - Correlation matrix (MFCs 4grams)

Apply PCA using a correlation matrix to visualize the results with MFCs 4-grams. We will look at the top 100 to 2000 MFCs 4-grams with an increment of 100 in each iteration.

Cosine Delta will be used as a distance metric.
```{r}
# PCA correlation - top 100-2000-100 incr.100 MFCs 4-grams
results_pca_4grams_cor <- stylo(frequencies = freqs_4grams, 
                                analysis.type = "PCR",
                                mfw.min = 100, mfw.max = 2000, increment = 100, 
                                distance.measure = "wurzburg", # Cosine Delta
                                custom.graph.title = "Who is the author?", 
                                pca.visual.flavour = "classic", 
                                write.pdf.file = TRUE, 
                                gui = TRUE) #GUI is set to TRUE to double check the parameters. In principle no additional change should be implemented. Hit "OK" and the results will be displayed after the PCA is done.
```
## Apply Bootstrap Consensus Tree - MFC 4-grams

### Load and prepare corpus for the validation of BCT
Load and prepare the correct corpus for the validation of BCT, following the same preprocessing steps.

```{r}
# load the corpus for the validation of BCT
raw_corpus_bct <- load.corpus(files = "all", corpus.dir = "../../../validation/validation_corpora/validation_corpus_BCT/", encoding = "UTF-8")

# tokenize the corpus
tokenized_corpus_bct <- txt.to.words.ext(raw_corpus_bct, corpus.lang = "Latin.corr", preserve.case = FALSE)
```

### Remove the pronouns
Remove pronouns from the corpus.

```{r}
# remove pronouns from the tokenized corpus
corpus_no_pronouns_bct <- delete.stop.words(tokenized_corpus_bct, stop.words = stylo.pronouns(corpus.lang = "Latin.corr"))

# list of pronouns removed
stylo.pronouns(corpus.lang = "Latin.corr")
```
### Extracting the features (character 4-grams)
Extract character 4-grams and add them to a frequency table.

```{r}
# Extract character 4-grams
corpus_char_4grams_bct <- txt.to.features(corpus_no_pronouns_bct, features = "c", ngram.size = 4)

# Create a frequency list of the 4-grams
frequent_features_4grams_bct <- make.frequency.list(corpus_char_4grams_bct, head = 5000)

# Create a table of frequencies for the 4-grams
freqs_4grams_bct <- make.table.of.frequencies(corpus_char_4grams_bct, features = frequent_features_4grams_bct, relative = TRUE)
```

```{r}
# BCT 4grams - top 100-2000-100 MFC 4 grams - consensus strength 0.5
bct_results_4grams <- stylo(frequencies = freqs_4grams_bct, 
                            distance.measure = "wurzburg", #cosine delta
                            analysis.type = "BCT", 
                            mfw.min = 100, mfw.max = 2000, increment = 100, 
                            custom.graph.title = "Who is the author?", 
                            write.pdf.file = TRUE, 
                            gui = TRUE) # GUI only to doublecheck. In principle no change should be implemented
```

# Conclusions
From the methods and their variations run above, we can observe that all of the "unknown" texts have been successfully attributed to the "correct" author.

    unknown0.txt (i.e., Amores) to Ovid
    unknown1.txt (i.e., Thebaid book 1) to Statius
    unknown2.txt (i.e., Satire 4) to Persius

Especially the last case, Satire 4 by Persius is interesting. The length of the text is minuscule compared to the other texts in the corpus; it consists of only 342 tokens, thus the distance from the other texts. The other "not-so-tricky" case is the Medicamina Faciei Femineae by Ovid which has only 613 tokens (i.e., the second shortest text in our validation dataset).